
import os
import glob
import random
import darknet
import time
import cv2
import numpy as np
import darknet
from queue import Queue


""""
åœ¨darknet_images.pyåŸºç¡€ä¸Šï¼Œåšäº†ä¸€äº›ä¿®æ”¹ï¼š
    å»æ‰ä¸€äº›å‡½æ•°
    æ·»åŠ è·¯å¾„
    æ·»åŠ åä¼˜åŒ–å‡½æ•°

"""


def load_images(images_path):
    return glob.glob(
            os.path.join(images_path, "*.jpg")) + \
            glob.glob(os.path.join(images_path, "*.png")) + \
            glob.glob(os.path.join(images_path, "*.jpeg"))


def image_detection(image, network, class_names, class_colors, thresh):
    # Darknet doesn't accept numpy images.
    # Create one with image we reuse for each detect
    width = darknet.network_width(network)
    height = darknet.network_height(network)
    darknet_image = darknet.make_image(width, height, 3)
    print("image_detection:" , width,height)
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_resized = cv2.resize(image_rgb, (width, height),
                               interpolation=cv2.INTER_LINEAR)
    darknet.copy_image_from_bytes(darknet_image, image_resized.tobytes())
    
    print("darknet.detect_image")
    detections = darknet.detect_image(network, class_names, darknet_image, thresh=thresh)
    darknet.free_image(darknet_image)
    
    print("detections")
    print(detections)
    print("darknet.draw_boxes")
    image = darknet.draw_boxes(detections, image_resized, class_colors)
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB), detections


def convert2relative(image, bbox):
    """
    YOLO format use relative coordinates for annotation
    """
    x, y, w, h = bbox
    height, width, _ = image.shape
    return x/width, y/height, w/width, h/height

def load_network():
    # load network
    config_file="./dataspace/wj3_v16.cfg"
    data_file="./dataspace/soot.data"
    weights="./pp_6000.weights"
    batch_size = 1
    random.seed(3)  # deterministic bbox colors
    network, class_names, class_colors = darknet.load_network(
        config_file,
        data_file,
        weights,
        batch_size
    )
    return network, class_names, class_colors


def calcuFrameAbs(previousFrame,currentFrame,thresh):
    # è®¡ç®—å½“å‰å¸§å’Œå‰å¸§çš„ä¸åŒ 
    frameDelta = cv2.absdiff(previousFrame, currentFrame) 
    
    # åœ¨frameDeltaä¸­æ‰¾å¤§äº20ï¼ˆé˜ˆå€¼ï¼‰çš„åƒç´ ç‚¹, å¯¹åº”ç‚¹è®¾ä¸º255
    # æ­¤å¤„é˜ˆå€¼å¯ä»¥å¸®åŠ©é˜´å½±æ¶ˆé™¤, å›¾åƒäºŒå€¼åŒ– 
    frameDelta = cv2.threshold(frameDelta, thresh, 255, cv2.THRESH_BINARY)[1] 
    
    # ç»“æ„å…ƒç´ (å†…æ ¸çŸ©é˜µ)çš„å°ºå¯¸
    g_nStructElementSize=3
    
    # è·å–è‡ªå®šä¹‰æ ¸
    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(7,7))

    # å»é™¤å›¾åƒå™ªå£°: è…èš€, è†¨èƒ€(å½¢æ€å­¦å¼€è¿ç®—) 
    
    # è…èš€
    frameDelta=cv2.erode(frameDelta, kernel,3) 
    # è†¨èƒ€
    frameDelta = cv2.dilate(frameDelta, kernel,3) 
    
    return frameDelta

def bbox2points(bbox):
    x, y, w, h = bbox
    xmin = int(round(x - (w / 2)))
    xmax = int(round(x + (w / 2)))
    ymin = int(round(y - (h / 2)))
    ymax = int(round(y + (h / 2)))
    return xmin, ymin, xmax, ymax


def convert2relative(bbox):
    """
    YOLO format use relative coordinates for annotation
    """
    x, y, w, h  = bbox
    _height     = darknet_height
    _width      = darknet_width
    return x/_width, y/_height, w/_width, h/_height


def convert2original(image, bbox):
    x, y, w, h = convert2relative(bbox)

    image_h, image_w, __ = image.shape

    orig_x       = int(x * image_w)
    orig_y       = int(y * image_h)
    orig_width   = int(w * image_w)
    orig_height  = int(h * image_h)

    bbox_converted = (orig_x, orig_y, orig_width, orig_height)

    return bbox_converted


def isHasMove(image,detections,frameDelta,thresh):
    # frameDeltaå½’ä¸€åŒ–å¤„ç†
    # assert len(frameDelta)  , "frameDelta must be single channel "
    frameDelta = frameDelta // 255
    # è®¡ç®—bboxåœ¨frameDeltaå¯¹åº”ä½ç½®çš„åŠ¨æ€ä¿¡æ¯æ•°é‡
    for _, confidence, bbox in detections:
        x,y,w,h=bbox
        xmin,ymin,xmax,ymax = bbox2points(bbox)
        crop = frameDelta[xmin:xmax,ymin:ymax]
        # è®¡ç®—åŠ¨æ€ä¿¡æ¯å æ¯”
        sigma = np.sum(crop) / (w * h)
        if sigma < thresh:
            # int(confidence) < 30.0
            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255,0,0), 1)
            cv2.putText(image, "suppression", (xmax, ymax - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,255), 1)
            print("=====suppression this bounding box")
    return image


# åŠ è½½å›¾ç‰‡æ•°æ®
def load_data(frame_queue,image_path="dataspace/img"):
    # åŠ è½½æ•°æ®
    # image_names = ['data/horses.jpg', 'data/horses.jpg', 'data/eagle.jpg']
    image_names=load_images(image_path)
    image_names.sort()
    print("total image:",len(image_names))
    
    # images = [cv2.imread(image) for image in image_names]
    for image_name in image_names:
        image=cv2.imread(image_name)
        if image is not None:
            frame_queue.put(image)
    print("cv2.imread succ")

# åŠ è½½è§†é¢‘æ•°æ®
def load_video_data(frame_queue,input_path):
    cap = cv2.VideoCapture(input_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_queue.put(frame)
    cap.release()
    print("video imread succ")

# å†…å­˜ä¸å¤Ÿï¼Œå‚è€ƒdataloader: ä¸€æ¬¡åŠ è½½ä¸€ä¸ªæ‰¹é‡
def data_loader(cap,frame_queue,batch_size):
    frame_queue.queue.clear()
    cnt=0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_queue.put(frame)
        cnt+=1
        if cnt == batch_size:
            break
    print("batch_size frame of video imread succ")

if __name__=='__main__':
    # å°†å¤„ç†ä¹‹åçš„å¸§ï¼Œä¿å­˜åœ¨save_pathæ–‡ä»¶å¤¹
    save_path= "dataspace/saveImg"
    frame_queue = Queue()

    # load network
    network, class_names, class_colors = load_network()
    print("load network succ")

    darknet_width = darknet.network_width(network)
    darknet_height = darknet.network_height(network)

    input_path="./dataspace/test.mp4"
    cap = cv2.VideoCapture(input_path)

    # è§†é¢‘æ€»å¸§æ•°
    frame_total = int(cap.get(7)) 
    print("frame_total: ",frame_total)   
    # ä¸€æ¬¡åŠ è½½batch_sizeå¼ å›¾ç‰‡
    batch_size=25


    print("loop ===============")
    for index in range(0, frame_total, batch_size):
        data_loader(cap,frame_queue,batch_size)
        print("queue size: ",frame_queue.qsize())
        print("loader ============================")
        ############################### å¸§å·®
        frame_thresh=20
        previousFrame=None

        thresh=0.25
        while not frame_queue.empty():
            image=frame_queue.get()
            ################################## å¸§å·®
            currentFrame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # å¦‚æœç¬¬ä¸€å¸§æ˜¯Noneï¼Œå¯¹å…¶è¿›è¡Œåˆå§‹åŒ– 
            if previousFrame is None: 
                previousFrame = currentFrame
                continue
            # å¾—åˆ°å¸§å·®ï¼šå•é€šé“äºŒå€¼å›¾
            frameDelta = calcuFrameAbs(previousFrame,currentFrame,0.001) 
        
            # å½“å‰å¸§è®¾ç½®ä¸ºä¸‹ä¸€å¸§çš„å‰å¸§ 
            previousFrame = currentFrame.copy()
            ################################## å¸§å·®

            ################################### æ£€æµ‹å›¾ç‰‡
            height,width,_ = image.shape
            print("width, height", width, height)
            
            # frameä¿å­˜åŸå›¾
            frame = image.copy()
            # detect image, image type is np.adarray()
            print("image_detection *****")
            
            image, detections = image_detection(image, network, class_names, class_colors,thresh)
            
            print("detections ============= ")
            print(detections)
            print("detections ============= ")
            # è½¬æ¢åæ ‡ï¼Œä¸åŸå›¾å¤§å°ç›¸å¯¹åº”
            detections_adjusted=[]
            for label, confidence, bbox in detections:
                bbox_adjusted = convert2original(frame, bbox)
                detections_adjusted.append((str(label), confidence, bbox_adjusted))
            
            # åœ¨åŸå›¾ä¸Šï¼Œç”»è¾¹ç•Œæ¡†
            image = darknet.draw_boxes(detections_adjusted, frame, class_colors)
            
            ################################### é€»è¾‘åˆ¤æ–­
            if len(detections_adjusted) != 0 :
                # æœ‰è¾¹ç•Œæ¡†ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰è¿åŠ¨ä¿¡æ¯ï¼Œå°†ç»“æœä¿®æ”¹åˆ°åŸå›¾
                image=isHasMove(frame,detections_adjusted,frameDelta,0.01)
            # æ˜¾ç¤º
            # cv2.imshow('Inference', image)
            # ä¿å­˜
            save_image_name=save_path + "/" + str(index).zfill(5) + ".jpg"
            # cv2.imwrite( save_image_name , image_resized)
            cv2.imwrite( save_image_name , image)
            print("image writed to ",save_image_name)
            
            index+=1
    cap.release()

    





# if __name__=='__main__':

#     save_path= "dataspace/saveImg"
#     frame_queue = Queue()

#     # # åŠ è½½æ•°æ®ï¼šå›¾ç‰‡
#     # image_path="dataspace/img"
#     # load_data(frame_queue,image_path)
    
#     # åŠ è½½æ•°æ®ï¼šè§†é¢‘
#     input_path="./dataspace/test.mp4"
#     load_video_data(frame_queue,input_path) 
    
#     print("queue size: ",frame_queue.qsize())

#     # load network
#     network, class_names, class_colors = load_network()
#     print("load network succ")

#     darknet_width = darknet.network_width(network)
#     darknet_height = darknet.network_height(network)





#     #####  å¸§å·®
#     frame_thresh=20
#     previousFrame=None
#     #####  å¸§å·®

#     thresh=.25
#     index = 1
#     while not frame_queue.empty():
#         image=frame_queue.get()
#         ################################## å¸§å·®
#         currentFrame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#         # å¦‚æœç¬¬ä¸€å¸§æ˜¯Noneï¼Œå¯¹å…¶è¿›è¡Œåˆå§‹åŒ– 
#         if previousFrame is None: 
#             previousFrame = currentFrame
#             continue
#         # å¾—åˆ°å¸§å·®ï¼šå•é€šé“äºŒå€¼å›¾
#         frameDelta = calcuFrameAbs(previousFrame,currentFrame,0.01) 
    
#         # å½“å‰å¸§è®¾ç½®ä¸ºä¸‹ä¸€å¸§çš„å‰å¸§ 
#         previousFrame = currentFrame.copy()
#         ################################## å¸§å·®

#         ################################### æ£€æµ‹å›¾ç‰‡
#         height,width,_ = image.shape
#         print("width, height", width, height)
        
#         # frameä¿å­˜åŸå›¾
#         frame = image.copy()
#         # detect image, image type is np.adarray()
#         print("image_detection =========")
#         try:
#             # free pointeræŠ¥é”™ï¼Œæ²¡æ‰¾åˆ°åŸå› ï¼ŒåŠ ä¸ªtryğŸ•ä¸€ä¼š
#             image, detections = image_detection(image, network, class_names, class_colors,thresh)
#         except:
#             continue
#         print("detections ============= ", detections)

#         # è½¬æ¢åæ ‡ï¼Œä¸åŸå›¾å¤§å°ç›¸å¯¹åº”
#         detections_adjusted=[]
#         for label, confidence, bbox in detections:
#             bbox_adjusted = convert2original(frame, bbox)
#             detections_adjusted.append((str(label), confidence, bbox_adjusted))
#             image = darknet.draw_boxes(detections_adjusted, frame, class_colors)
        
#         # åœ¨åŸå›¾ä¸Šï¼Œç”»è¾¹ç•Œæ¡†
#         image = darknet.draw_boxes(detections_adjusted, frame, class_colors)
        
#         ################################### é€»è¾‘åˆ¤æ–­
#         if len(detections_adjusted) != 0 :
#             # æœ‰è¾¹ç•Œæ¡†ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰è¿åŠ¨ä¿¡æ¯ï¼Œå°†ç»“æœä¿®æ”¹åˆ°åŸå›¾
#             image=isHasMove(frame,detections_adjusted,frameDelta)
#         # æ˜¾ç¤º
#         # cv2.imshow('Inference', image)
#         # ä¿å­˜
#         save_image_name=save_path + "/" + str(index).zfill(5) + ".jpg"
#         # cv2.imwrite( save_image_name , image_resized)
#         cv2.imwrite( save_image_name , image)
#         print("image writed to ",save_image_name)
        
#         index+=1

#     # if cv2.waitKey() & 0xFF == ord('q'):
#     #     break


